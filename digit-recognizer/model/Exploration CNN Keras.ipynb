{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to CNN Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "sns.set(style='white', context='notebook', palette='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "import os\n",
    "path = os.path.dirname(os.path.abspath(''))\n",
    "train = pd.read_csv(path + '/data/train.csv')\n",
    "test = pd.read_csv(path + '/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_train = train['label']\n",
    "\n",
    "# Drop 'label' column\n",
    "X_train = train.drop(labels=['label'], axis=1)\n",
    "\n",
    "# free some space\n",
    "del train\n",
    "\n",
    "g = sns.countplot(Y_train)\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Check for null & missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data\n",
    "X_train.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count       784\n",
       "unique        1\n",
       "top       False\n",
       "freq        784\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().any().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no missing value in training set, neither testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Normailization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a grayscale normalization to reduce the effect of illumination differences.\n",
    "\n",
    "And CNN converg faster on \\[0...1\\] then on \\[0...255\\] ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normailze the data\n",
    "X_train = X_train / 255.0\n",
    "test = test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the images has been stock into pandas.Dataframe as 1D vectors of 784 values. We reshape all data to 28*28*1 3D matrices.\n",
    "\n",
    "Keras requires an extra dimention in the end, which correspond to channels. MNIST images are gray scaled so it use only 1 channel. For RGB images, there will be 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape image in 3 dimensions\n",
    "X_train = X_train.values.reshape(-1, 28, 28, 1)\n",
    "test = test.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels to one-hot-vectors\n",
    "Y_train = to_categorical(Y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 2\n",
    "# Split the train and the validation set for the fitting\n",
    "x_train, X_val, Y_trian, Y_val = train_test_split(\n",
    "        X_train, Y_train, test_size = 0.1,\n",
    "        random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the train set into two pars: 10% as validation set, and 90% as training set.\n",
    "\n",
    "Since we have a balanced dataset (each label has a relatively equal population), we split randomly here. If data is unbalanced, **stratify = True** should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some examples\n",
    "g = plt.imshow(X_train[0][:, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used Keras Sequential API here, where you have just to add one layer at a time, starting from the input.\n",
    "\n",
    "The first is the convolutional (Conv2D) layer. We use 32 filters for the first two layers and 64 for the last two. \n",
    "\n",
    "The second is the pooling (MaxPool2D)layer. This layer works as downsample layer in the network.\n",
    "\n",
    "Combining this two kinds of layer, CNN are able to combine local features and learn more global features of the image.\n",
    "\n",
    "The activation here is the most common one, ReLu; except for output layer is activated by softmax.\n",
    "\n",
    "Dropout is a regularization method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Define the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the CNN model.\n",
    "#My CNN architecture is In -> [[Conv2D->ReLu]*2 -> MaxPool2D -> Dropout]*2 -> Flatten -> Dense -> Droupout -> Out.\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding='Same',\n",
    "                activation = 'relu', input_shape = (28, 28,1 )))\n",
    "model.add(Conv2D(filters = 32, kernel_size = (5, 5), padding='Same',\n",
    "                activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding='Same',\n",
    "                activation = 'relu', input_shape = (28, 28,1 )))\n",
    "model.add(Conv2D(filters = 64, kernel_size = (5, 5), padding='Same',\n",
    "                activation = 'relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Setup optimizer and annealer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizor = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer = optimizor, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a learning rete annealer\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
    "                                            patience=3,\n",
    "                                            verbose=1,\n",
    "                                            factor=.5,\n",
    "                                            min_lr=0.00001\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1 \n",
    "batch_size = 86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 42000 samples, validate on 4200 samples\n",
      "Epoch 1/1\n",
      " - 530s - loss: 0.2807 - acc: 0.9125 - val_loss: 0.0874 - val_acc: 0.9748\n"
     ]
    }
   ],
   "source": [
    "# Without data augmentation, acc = \n",
    "history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epoch,\n",
    "                   validation_data = (X_val, Y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With data augmentation to prevent overfitting\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset \n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=10, # randomly rotate images inthe range ( degrees, 0 to 180)\n",
    "    zoom_range=.1, # randomly zoom image\n",
    "    width_shift_range=.1, # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=.1, # randomly shift images wertically (fraction of total height)\n",
    "    horizontal_flip=False, # randomly flip images\n",
    "    vertical_flip=False, # randomly flip images\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "history = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=batch_size,\n",
    "                                          epochs=epoch, validation_data=(X_val, Y_val),\n",
    "                                          verbose=2, steps_per_epoch=X_trian.shpae[0] // batch_size,\n",
    "                                          callback=[leraning_rate_reduction])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
